{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a4d0ce5e-6fc8-4be1-9496-a1facaa90de0",
   "metadata": {},
   "source": [
    "## **株価データ**\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f60573f6-1d3c-4a35-851a-7d7cded13280",
   "metadata": {},
   "source": [
    "\n",
    "#### <span style=\"color: red\">**Apple の株価（終値）では、区間ごとの平均値、分散、自己共分散が大きく異なる。**</span>\n",
    "<img src=\"figs/0.jpg\" width=\"1000px\">\n",
    "\n",
    "#### ADF 検定：<span style=\"color: red\">**Apple の株価（終値）は非定常過程**</span>\n",
    "<img src=\"figs/1.jpg\" width=\"800px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd6bc113-bf88-477c-a724-55500ea508ba",
   "metadata": {},
   "source": [
    "---\n",
    "### ADF 検定（augmented Dickey-Fuller test）\n",
    "Augmented Dickey-Fuller（ADF）検定は、時系列データが単位根過程（非定常過程）であるかどうかを検定するための手法。この検定は、特に経済学や財務学、気象学、エンジニアリングなど、多くの分野で非定常時系列データを扱う際によく用いられる。\n",
    "\n",
    "#### 基本的なアイデア\n",
    "\n",
    "単位根過程は、時系列がランダムウォークに似た挙動を示す場合に用いられるモデル。ランダムウォークは非定常過程であり、その統計的性質（平均や分散など）は時間に依存する。ADF検定は、時系列がこのような非定常性を持つかどうかを調べるために用いられる。\n",
    "\n",
    "#### 数学的なモデル\n",
    "\n",
    "ADF検定の数学的なモデルは、以下のような回帰方程式に基づいている：\n",
    "\n",
    "$$\n",
    "\\Delta y_t = \\alpha + \\beta t + \\gamma y_{t-1} + \\delta_1 \\Delta y_{t-1} + \\delta_2 \\Delta y_{t-2} + \\cdots + \\delta_p \\Delta y_{t-p} + \\epsilon_t\n",
    "$$\n",
    "\n",
    "ここで、$\\Delta y_t = y_t - y_{t-1}\\ .$\n",
    "\n",
    "#### 帰無仮説と対立仮説\n",
    "\n",
    "ADF検定の帰無仮説（null hypothesis）と対立仮説（alternative hypothesis）は次のように設定される：\n",
    "\n",
    "- 帰無仮説（$H_0$）：$\\gamma = 0$（単位根が存在する、つまり非定常である）\n",
    "- 対立仮説（$H_a$）：$\\gamma < 0$（単位根が存在しない、つまり定常である）\n",
    "\n",
    "#### 検定結果の解釈\n",
    "\n",
    "ADF検定を行った後、p値を用いて帰無仮説を評価する。\n",
    "\n",
    "- p値 < 0.05: 帰無仮説を棄却し、対立仮説を採用（データは定常）\n",
    "- p値 >= 0.05: 帰無仮説を棄却できない（データは非定常）\n",
    "\n",
    "この検定によって、時系列データが定常性を持つかどうかを厳密に評価することができる。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "357c6605-ad3e-47e9-a665-157422cbbe5d",
   "metadata": {},
   "source": [
    "---\n",
    "### 単位根\n",
    "単位根（Unit Root）は、時系列分析において非定常性を調べる一つの手法であり、特に経済学やファイナンスでよく用いられる。単位根が存在するということは、時系列データが非定常であるという指標になる。非定常な時系列データは、その統計的性質（平均、分散など）が時間に依存するため、多くの統計的手法が適用できなくなる。\n",
    "\n",
    "時系列データ $y_t$ に対する一般的な AR(1)（自己回帰モデル）式は以下のように表される。\n",
    "\n",
    "$$\n",
    "y_t = c + \\phi y_{t-1} + \\epsilon_t\\ .\n",
    "$$\n",
    "\n",
    "ここで、$c$ は定数項、$\\phi$ は自己回帰係数、$\\epsilon_t$ はホワイトノイズ。\n",
    "\n",
    "**このモデルにおいて、$\\phi = 1$ の場合を特に単位根が存在する、または単位根過程であると言う。**このとき、時系列はランダムウォークになるか、またはランダムウォークにトレンドが加わる形になる。\n",
    "\n",
    "単位根の有無を調べるためには、いくつかの統計的検定（単位根検定）が存在する。例えば、次のような検定がよく用いられる。\n",
    "\n",
    "- Dickey-Fuller検定\n",
    "- Augmented Dickey-Fuller（ADF）検定\n",
    "- Phillips-Perron（PP）検定\n",
    "- Kwiatkowski-Phillips-Schmidt-Shin（KPSS）検定\n",
    "\n",
    "これらの検定は、時系列データが単位根を持つ（非定常である）かどうかを判断するのに役立つ。単位根が存在する場合、データを定常にするための前処理（例えば、差分を取る）が必要になる。\n",
    "\n",
    "注意点として、単位根検定が帰無仮説を棄却できなかったからと言って、その時系列が定常であるわけではないことである。単にその検定で単位根の有無を確認することができなかっただけで、他の形の非定常性が存在する可能性がある。それを調べるには他の手法（例えば、KPSS検定など）が必要。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bb1e9b4-7ba7-46f3-8d98-e249970df623",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "### 定常過程の定義：\n",
    "定常過程（stationary process）とは、統計的な性質が時間に依存しない時系列のこと。定常過程には**弱定常**（weak-sense stationary）と**強定常**（strong-sense stationary）の2つのタイプがあり、多くの場合、弱定常が議論の対象となる。\n",
    "\n",
    "**弱定常過程の特徴**として以下の条件が挙げられる：\n",
    "\n",
    "1. 平均が一定：時間に依存しない。\n",
    "   $$\n",
    "   \\mu(t) = \\mu\n",
    "   $$\n",
    "   \n",
    "2. 分散が一定：時間に依存しない。\n",
    "   $$\n",
    "   \\sigma^2(t) = \\sigma^2\n",
    "   $$\n",
    "\n",
    "3. 自己共分散はラグ（遅延）にのみ依存：2つの時点間の自己共分散は、それらの時点がどれだけ離れているか（ラグ）にのみ依存し、具体的な時間には依存しない。\n",
    "\n",
    "   $$\n",
    "   \\text{Cov}(X_t, X_{t+k}) = \\text{Cov}(X_{t'}, X_{t'+k}) \\quad \\text{for all } t, t'\n",
    "   $$\n",
    "\n",
    "この3番目の条件が最も重要で、自己共分散がラグにのみ依存する場合、その時系列は定常であると言える。つまり、自己共分散が時間の具体的な値に依存せず、ラグにのみ依存する形状を持つとき、その時系列は弱定常過程と見なされる。弱定常の場合、自己共分散や自己相関のグラフは一般に時間に依存しない一定のパターンを示す。これは定常過程の特徴としてよく用いられる。\n",
    "\n",
    "**強定常過程の特徴**として以下の条件が挙げられる：\n",
    "\n",
    "確率過程が時間の平行移動に対して不変であるときに用いられる概念。具体的には、任意の時刻 $t_1, t_2, \\ldots, t_n$ と任意の時間間隔 $h$ に対して、確率分布が以下のように等しいとき、確率過程 $X(t)$ は強定常であると言う。\n",
    "\n",
    "$$\n",
    "F_X(x_1, t_1; x_2, t_2; \\ldots; x_n, t_n) = F_X(x_1, t_1+h; x_2, t_2+h; \\ldots; x_n, t_n+h)\n",
    "$$\n",
    "\n",
    "ここで $F_X$ は $X(t)$ の結合確率分布関数。\n",
    "\n",
    "強定常過程では、過程全体の統計的特性が時間に依存しないため、様々な時系列解析の応用が容易になる。強定常という性質はかなり厳格な条件を課しているので、現実のデータ解析で出くわす確率過程がこれに完全に当てはまることは稀。それよりも緩やかな条件を満たす弱定常過程の方が、よく使用される。弱定常過程では、平均と自己共分散が時間不変であればよいとされている。\n",
    "\n",
    "#### 前回の結論は、<span style=\"color: red\">**Apple の株価は定常過程ではない**</span>、と言い換えることができる。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59519a34-202e-4f37-94c3-9531cfed4a8d",
   "metadata": {},
   "source": [
    "---\n",
    "### 時系列解析では、定常過程（特に弱定常過程）を考える。なぜ？\n",
    "#### 1. 単純化と一般化：\n",
    "\n",
    "定常性は解析を単純化する。平均、分散、自己共分散などが時間に依存しないため、これらのパラメータを一度だけで推定することができる。これにより、過程の一般的な特性を簡潔に表現することができる。\n",
    "\n",
    "#### 2. 予測：\n",
    "\n",
    "定常過程は将来の予測に有用。過程が定常であれば、過去のデータを用いて未来を予測する際の信頼性が高くなる。\n",
    "\n",
    "#### 3. 統計的有効性：\n",
    "\n",
    "多くの時系列の統計手法（例えば、ARIMA モデルや Fourier 解析など）は、定常性を前提としている。非定常な時系列データにこれらの手法を直接適用すると、誤った結論につながる可能性がある。\n",
    "\n",
    "#### 4. 操作の容易性：\n",
    "\n",
    "定常過程は、他の過程との畳み込みや合成、フィルタリングなど、各種の操作が数学的に容易。これは、信号処理や自動制御などの工学的応用でも有用。\n",
    "\n",
    "#### 5. 理論的洞察：\n",
    "\n",
    "定常性は理論的な分析においても重要。例えば、定常過程の性質を理解することで、非定常過程についてもより深い洞察を得ることができる場合がある。\n",
    "\n",
    "以上のように、定常性は時系列解析における基本的かつ強力な仮定であり、多くの理由からその考慮が推奨される。ただし、現実のデータが常に定常であるわけではないため、データが非定常である場合には適切な前処理（例えば、差分を取る、季節調整を行うなど）が必要となることも多い。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ef7178f-ce56-46dc-aff8-a0bfef62f61d",
   "metadata": {},
   "source": [
    "---\n",
    "### 定常化\n",
    "\n",
    "- 非定常過程を定常過程へ変換\n",
    "\n",
    "#### **単純収益率（リターン）**\n",
    "\n",
    "実務では、株などの金融資産の価格よりも収益率（リターン）が重要。例えば、ある人が投資して 100 円儲かったとする。以下の 2 つのケースを考えてみよう。\n",
    "\n",
    "1. 100 円投資して 200 円になったから 100 円儲かった。\n",
    "\n",
    "2. 1000 円投資して 1100 円になったから 100 円儲かった。\n",
    "\n",
    "どちらの方が、うまく運用したと言えるか？この質問に答えるために、時刻 $t$ での価格を $x_t$ と書いて、単純収益率（リターン）と呼ばれる量 $R_t$ を次のように定義する：\n",
    "\n",
    "$$\n",
    "R_t =\\frac{x_t-x_{t-1}}{x_{t-1}}\\ .\n",
    "$$\n",
    "\n",
    "これは、株などの金融資産の価格変動をパーセンテージで表したもの。この式にしたがって、上の 2 つのケースで計算すると\n",
    "\n",
    "1. $\\quad R_t=\\cfrac{200-100}{100}=1\\quad\\longrightarrow\\quad 100\\%$\n",
    "\n",
    "2. $\\quad R_t=\\cfrac{1100-1000}{1000}=0.1\\quad\\longrightarrow\\quad 10\\%$\n",
    "\n",
    "この結果から、1. のケースの方がリターンが大きく、うまく運用したとわかる。\n",
    "\n",
    "#### 単純収益率の特徴：\n",
    "1. **解釈が容易**\n",
    "   - 単純収益率はパーセンテージで表されるため、投資の収益性を直感的に理解しやすい。\n",
    "2. **加法的ではない**\n",
    "   - 複数の期間にわたる単純収益率を合計することはできない。例えば、2日間の連続した単純収益率を合計しても、その2日間全体の収益率にはならない。\n",
    "3. **値域**\n",
    "   - 単純収益率は-1から無限大までの範囲を取ることができる。例えば、価格が0になる場合、収益率は-1になる。\n",
    "4. **短期間の変動を捉える**\n",
    "   - 単純収益率は短期間（日次、週次など）の価格変動を評価するのに適している。\n",
    "\n",
    "注意点として、長期間にわたる投資の収益性を評価する場合や、複数の期間を合計する場合には、複利収益率や対数収益率を使用することが推奨されることがある。\n",
    "\n",
    "\n",
    "#### **対数収益率（対数リターン）**\n",
    "\n",
    "時刻 $t$ での価格を $x_t$ と書いて、対数リターン（対数収益率）と呼ばれる量 $r_t$ を次のように定義する：\n",
    "\n",
    "$$r_t=\\log(x_t)-\\log(x_{t-1})=\\log\\frac{x_t}{x_{t-1}}\\ .$$\n",
    "\n",
    "対数リターン（対数収益率）を利用する理由はいくつかあり、主に計算の便利性、統計的性質、および解釈のしやすさに関連している。\n",
    "\n",
    "#### 単純収益率の特徴：\n",
    "1. 計算の便利性\n",
    "   - **合成性**（Composability）：対数収益率は時間を通じて累積することが容易。連続する期間における対数収益率を計算する場合、単純にそれぞれの期間の対数収益率を足し合わせればよい。これは、複利効果を考慮する際に非常に便利。\n",
    "2. 統計的性質\n",
    "   - **正規性**：対数収益率は、しばしば（しかし必ずしもではない）正規分布に従いやすい。これは、多くの統計的手法やリスクモデルが正規分布を前提としているため、解析がしやすくなる。\n",
    "   - **定常性**: 対数収益率は、原系列が非定常な場合でもしばしば定常性をもたらす。これにより、時系列分析が容易になる。\n",
    "3. 解釈のしやすさ\n",
    "   - **パーセンテージリターン**：対数収益率はパーセンテージの変化として解釈することが容易であり、そのために金融市場などで広く用いられている。\n",
    "4. 数学的な扱いやすさ\n",
    "   - **微分**：対数関数の微分は、数学的に扱いやすい形になるため、対数収益率は連続時間モデル（例：ブラック・ショールズモデル）でよく使用される。\n",
    "\n",
    "以上のように、対数収益率は計算の便利性、統計的性質、解釈の容易さ、数学的な扱いやすさなど、多くの理由から使用される。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ba90c6d-3cdc-4117-b0b6-11cd44bd73b3",
   "metadata": {},
   "source": [
    "---\n",
    "### 単純収益率と対数収益率のどちらを用いるべきか？\n",
    "\n",
    "単純収益率（単純リターン）と対数収益率（対数リターン）のどちらが「優れている」というのは、具体的な用途や目的に依存する。それぞれには利点と制限がある。\n",
    "\n",
    "#### 単純収益率（単純リターン）\n",
    "\n",
    "- ##### 利点：\n",
    "   - **直感的理解**: リターンは非常に直感的であり、価格がどれだけ上がったか（または下がったか）を簡単に把握できる。\n",
    "   - **短期取引**: 非常に短期間（例えば、数日または数週間）での収益を評価する場合、リターンは適切な選択であることが多い。\n",
    "\n",
    "- ##### 制限：\n",
    "   - **合成が難しい**: 異なる時間間隔でのリターンを合成する際には、複利計算が必要となり、計算が煩雑になる場合がある。\n",
    "  \n",
    "#### 対数収益率（対数リターン）\n",
    "\n",
    "- ##### 利点：\n",
    "   - **合成性**: 連続する期間の対数収益率は、単に足し合わせることで累積対数収益率が得られる。\n",
    "   - **統計的性質**: 対数収益率はしばしば正規分布に近い性質を持ち、定常性も高いため、統計的モデリングが容易。\n",
    "   - **長期取引**: 長期間にわたる投資の評価や、連続時間モデルを用いる金融工学的な分析に適している。\n",
    "\n",
    "- ##### 制限：\n",
    "   - **直感性が低い**: 対数収益率は一般の人々には直感的でない場合が多く、理解が難しいことがある。\n",
    "\n",
    "#### 結論\n",
    "\n",
    "単純収益率と対数収益率、どちらが優れているかは、具体的な状況や用途に依存する。短期的な取引や、一般の人々に結果を説明する際には単純収益率が有用。一方で、長期的な投資評価や高度な統計的分析を行う際には、対数収益率がしばしば用いられる。それぞれの用途に最適な指標を選ぶことが重要。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c8dcd8a-e26a-4cd2-923f-9c590cc8944a",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "#### **課題**\n",
    "1. 添付したファイル data/AAPL.csv を pandas の DataFrame で表示せよ。index_col の値、index のフォーマットに注意すること。\n",
    "\n",
    "解答例\n",
    "\n",
    "<img src=\"figs/2.jpg\" width=\"600px\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4a1b7be2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-01-02</th>\n",
       "      <td>38.722500</td>\n",
       "      <td>39.712502</td>\n",
       "      <td>38.557499</td>\n",
       "      <td>39.480000</td>\n",
       "      <td>148158800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-03</th>\n",
       "      <td>35.994999</td>\n",
       "      <td>36.430000</td>\n",
       "      <td>35.500000</td>\n",
       "      <td>35.547501</td>\n",
       "      <td>365248800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-04</th>\n",
       "      <td>36.132500</td>\n",
       "      <td>37.137501</td>\n",
       "      <td>35.950001</td>\n",
       "      <td>37.064999</td>\n",
       "      <td>234428400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-07</th>\n",
       "      <td>37.174999</td>\n",
       "      <td>37.207500</td>\n",
       "      <td>36.474998</td>\n",
       "      <td>36.982498</td>\n",
       "      <td>219111200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-08</th>\n",
       "      <td>37.389999</td>\n",
       "      <td>37.955002</td>\n",
       "      <td>37.130001</td>\n",
       "      <td>37.687500</td>\n",
       "      <td>164101200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Open       High        Low      Close     Volume\n",
       "Date                                                             \n",
       "2019-01-02  38.722500  39.712502  38.557499  39.480000  148158800\n",
       "2019-01-03  35.994999  36.430000  35.500000  35.547501  365248800\n",
       "2019-01-04  36.132500  37.137501  35.950001  37.064999  234428400\n",
       "2019-01-07  37.174999  37.207500  36.474998  36.982498  219111200\n",
       "2019-01-08  37.389999  37.955002  37.130001  37.687500  164101200"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file_path = '/Users/shishishikakou/Downloads/データサイエンス特論/02/data/AAPL.csv'\n",
    "df_aapl = pd.read_csv(file_path, index_col='Date', parse_dates=True)\n",
    "\n",
    "# DataFrame を表示\n",
    "df_aapl.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcba1277",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_dj30 = pd.read_csv('/Users/shishishikakou/Downloads/データサイエンス特論/03/data/DJ30.tsv', sep='\\t', index_col=0)\n",
    "df_dj30"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb83ede7-314d-4543-a80e-31d54c18329f",
   "metadata": {},
   "source": [
    "2. 日付 $t$ での Open の株価を $O_t$ と書いて、 Close の株価を $C_t$ と書いて、それらの比の対数を対数収益率 $r_t$ とする：\n",
    "\n",
    "$$\n",
    "r_t=\\log\\left(\\frac{C_t}{O_t}\\right)\\ .\n",
    "$$\n",
    "\n",
    "これは、Open to Close のリターンと呼ばれる。すべての日付に対して $r_t$ を計算し、問題 1. で作った DataFrame に\n",
    "OtoC というコラムを追加せよ。その後、OtoC を可視化せよ。\n",
    "\n",
    "解答例\n",
    "\n",
    "<img src=\"figs/3.jpg\" width=\"700px\">\n",
    "\n",
    "<img src=\"figs/4.jpg\" width=\"700px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e78717b-f40e-4fa7-a65e-02661e650b9a",
   "metadata": {},
   "source": [
    "3. 対数収益率（OtoC）を 72 日ごとに区切った 14 区間に対して、平均値、分散、自己共分散（ラグが 10, 20, 30, 40, 50, 60, 70 の場合）を計算して pandas の DataFrame でまとよ。その後、matplotlib を使って、平均値のグラフ、分散のグラフ、自己共分散のグラフの 3 つのグラフで可視化せよ。時系列データ $r_t$ のラグ $k$ の自己共分散 $\\gamma(k)$ を以下の式で定義する：\n",
    "$$\n",
    "\\gamma(k) = \\frac{1}{N} \\sum_{t=1}^{N-k} (r_t - \\bar{r})(r_{t+k} - \\bar{r})\\ .\n",
    "$$\n",
    "ここで、\n",
    "   - $N$ はそれぞれの区間のデータ数（ここでは 72）\n",
    "   - $\\bar{r}$ はそれぞれの区間でのデータの平均\n",
    "   - $r_t$ は時点 $t$ におけるデータの値\n",
    "   - $k$ はラグ（遅延）\n",
    "\n",
    "<img src=\"figs/5.jpg\" width=\"800px\">\n",
    "\n",
    "解答例\n",
    "\n",
    "<img src=\"figs/6.jpg\" width=\"900px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b6a7b55-45f8-4e26-94e3-53d7843e2f0d",
   "metadata": {},
   "source": [
    "4. 課題 3. の結果から、平均値、分散、自己共分散が区間によって異なるが、終値に対して同じ解析をした時と比べて、大きさの違いは格段に小さくなっている。そのため、時系列が定常過程になっていると期待できる。ADF 検定（augmented Dickey-Fuller test）と KPSS（Kwiatkowski–Phillips–Schmidt–Shin）検定について調べ、それぞれの検定を行って確かめよ。\n",
    "\n",
    "解答例\n",
    "\n",
    "<img src=\"figs/7.jpg\" width=\"500px\">\n",
    "\n",
    "<img src=\"figs/8.jpg\" width=\"500px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a786711-882e-4c75-b4b2-b2077bc2b3c1",
   "metadata": {},
   "source": [
    "5. 自己相関、偏自己相関について調べよ。その後、Close と OtoC に対して、それらを計算した結果をグラフで可視化せよ。\n",
    "\n",
    "解答例\n",
    "\n",
    "<img src=\"figs/9.jpg\" width=\"900px\">\n",
    "\n",
    "<img src=\"figs/10.jpg\" width=\"900px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18e73624-1d87-4706-a8c8-aa43488fd326",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.5 ('.venv': poetry)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "341da08e999077c3541ec3fb91ddd1bfab6477091d7e281aa1f2989f38718526"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
